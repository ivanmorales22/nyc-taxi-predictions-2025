{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07ef0373",
   "metadata": {},
   "source": [
    "# Tarea 5\n",
    "- Ivan Morales, 10 de Octubre de 2025\n",
    "\n",
    "Realizaremos dos experimentos, cada uno con chid experiments\n",
    "\n",
    "    - Gradient Boost\n",
    "    - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8a33e",
   "metadata": {},
   "source": [
    "### Importar las librerias necesarias y establecer conexion con Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06037451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, mlflow\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "\n",
    "load_dotenv(override=True) # Cargar las variables de entorno desde el archivo .env\n",
    "EXPERIMENT_NAME = \"/Users/ivan.morales@iteso.mx/nyc-taxi-experiments\" \n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e3977b",
   "metadata": {},
   "source": [
    "Preparacion de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e256d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train_ene = read_dataframe('../data/green_tripdata_2025-01.parquet')\n",
    "df_train_feb = read_dataframe('../data/green_tripdata_2025-02.parquet')\n",
    "df_val = read_dataframe('../data/green_tripdata_2025-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e33f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 44218 entries, 0 to 46620\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               44218 non-null  int32         \n",
      " 1   lpep_pickup_datetime   44218 non-null  datetime64[us]\n",
      " 2   lpep_dropoff_datetime  44218 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     42295 non-null  object        \n",
      " 4   RatecodeID             42295 non-null  float64       \n",
      " 5   PULocationID           44218 non-null  object        \n",
      " 6   DOLocationID           44218 non-null  object        \n",
      " 7   passenger_count        42295 non-null  float64       \n",
      " 8   trip_distance          44218 non-null  float64       \n",
      " 9   fare_amount            44218 non-null  float64       \n",
      " 10  extra                  44218 non-null  float64       \n",
      " 11  mta_tax                44218 non-null  float64       \n",
      " 12  tip_amount             44218 non-null  float64       \n",
      " 13  tolls_amount           44218 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  44218 non-null  float64       \n",
      " 16  total_amount           44218 non-null  float64       \n",
      " 17  payment_type           42295 non-null  float64       \n",
      " 18  trip_type              42291 non-null  float64       \n",
      " 19  congestion_surcharge   42295 non-null  float64       \n",
      " 20  cbd_congestion_fee     42696 non-null  float64       \n",
      " 21  duration               44218 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(16), int32(1), object(3)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_ene.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74c1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88436 entries, 0 to 46620\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   VendorID               88436 non-null  int32         \n",
      " 1   lpep_pickup_datetime   88436 non-null  datetime64[us]\n",
      " 2   lpep_dropoff_datetime  88436 non-null  datetime64[us]\n",
      " 3   store_and_fwd_flag     84590 non-null  object        \n",
      " 4   RatecodeID             84590 non-null  float64       \n",
      " 5   PULocationID           88436 non-null  object        \n",
      " 6   DOLocationID           88436 non-null  object        \n",
      " 7   passenger_count        84590 non-null  float64       \n",
      " 8   trip_distance          88436 non-null  float64       \n",
      " 9   fare_amount            88436 non-null  float64       \n",
      " 10  extra                  88436 non-null  float64       \n",
      " 11  mta_tax                88436 non-null  float64       \n",
      " 12  tip_amount             88436 non-null  float64       \n",
      " 13  tolls_amount           88436 non-null  float64       \n",
      " 14  ehail_fee              0 non-null      float64       \n",
      " 15  improvement_surcharge  88436 non-null  float64       \n",
      " 16  total_amount           88436 non-null  float64       \n",
      " 17  payment_type           84590 non-null  float64       \n",
      " 18  trip_type              84582 non-null  float64       \n",
      " 19  congestion_surcharge   84590 non-null  float64       \n",
      " 20  cbd_congestion_fee     85392 non-null  float64       \n",
      " 21  duration               88436 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(16), int32(1), object(3)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.concat([df_train_ene, df_train_feb])\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7679b",
   "metadata": {},
   "source": [
    "Concatemos los datasets de enero y febrero para construir una base mas robusta para validar con los datos de marzo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151e371",
   "metadata": {},
   "source": [
    "Feature Engineering + One Hot Encoding, pipeline simple inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261653d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)\n",
    "\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "X_val = preprocess(df_val, dv)\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982fee37",
   "metadata": {},
   "source": [
    "Definir los dataset como objetos de *mlflow* para poderlos trackear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce020484",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = mlflow.data.from_numpy(X_train.data, targets=y_train, name=\"green_tripdata_2025-01&02\")\n",
    "validation_dataset = mlflow.data.from_numpy(X_val.data, targets=y_val, name=\"green_tripdata_2025-03\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyc-taxi-predictions-2025 (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
